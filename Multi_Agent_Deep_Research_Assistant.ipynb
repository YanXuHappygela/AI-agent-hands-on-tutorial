{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ubcuvZTZc6"
      },
      "source": [
        "# Multi-Agent Deep Research Assistant with Strands and AWS Bedrock\n",
        "\n",
        "**Author:** Tutorial by [Manus AI](https://manus.im/app)\n",
        "\n",
        "**Supervisor:** [Yan Xu](https://yanxuhappygela.github.io/yan-xu/)\n",
        "\n",
        "**Framework:** Strands Agents SDK  \n",
        "\n",
        "**Backend:** AWS Bedrock API  \n",
        "\n",
        "**Difficulty level:** Itermediate to Advanced\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to build a **multi-agent deep research assistant** using the Strands agent framework with AWS Bedrock as the backend. The system takes a research topic from the user and generates a comprehensive research report through collaborative agent teamwork.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "- How to set up Strands Agents with AWS Bedrock\n",
        "- How to create specialized agents with custom tools\n",
        "- How to implement the Swarm pattern for multi-agent collaboration\n",
        "- How to build a complete deep research system with 5 agents\n",
        "- How agents autonomously hand off tasks to each other\n",
        "\n",
        "### System Architecture\n",
        "\n",
        "Our system uses **5 specialized agents** working collaboratively:\n",
        "\n",
        "1. **Planning Agent**: Analyzes topics and creates research plans\n",
        "2. **Research Agent**: Gathers information from multiple sources\n",
        "3. **Analysis Agent**: Synthesizes data and extracts insights\n",
        "4. **Writing Agent**: Creates well-structured research content\n",
        "5. **Critic Agent**: Reviews and refines the final report\n",
        "\n",
        "Each agent has **2-3 specialized tools** to accomplish its tasks.\n",
        "\n",
        "### Why Strands\n",
        "<a href=\"https://ibb.co/pjN0znz3\"><img src=\"https://i.ibb.co/zVCnRNRS/Screenshot-2026-02-20-at-11-41-32-AM.png\" alt=\"Screenshot-2026-02-20-at-11-41-32-AM\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yro1JQC8TZc-"
      },
      "source": [
        "## 1. Installation and Setup\n",
        "\n",
        "First, let's install the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqAjIabsTZc_"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q strands-agents strands-agents-tools boto3 requests beautifulsoup4 ddgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZLosk1JTZdA"
      },
      "source": [
        "## 2. AWS Bedrock Configuration\n",
        "\n",
        "Pre-requisite:\n",
        "1. Setup AWS account (free credit $100): [register](https://signin.aws.amazon.com/signup?request_type=register)\n",
        "2. Go to IAM (Identity and Access Management) to create a new user\n",
        "3. Attach Policy \"AmazonBedrockFullAccess\" to the user\n",
        "4. Go to created user and Click \"Create access key\"\n",
        "\n",
        "Video tutorial: [Connect with Bedrock backend](https://youtu.be/-Wp3WdyzvXg?t=1078)\n",
        "\n",
        "**Alternative option**\n",
        "Setup a local ollama server running model locally:\n",
        "[Build your first FREE AI Agent](https://colab.research.google.com/drive/12Djry5TI_NPxlzH0hnITT7lPfe-K0_JX?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCEKP0nQTZdA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load AWS credentials from Colab secrets\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = userdata.get(\"AWS_DEFAULT_REGION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X32AONopTZdB"
      },
      "source": [
        "## 3. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi9X8MPITZdB"
      },
      "outputs": [],
      "source": [
        "from strands import Agent, tool\n",
        "from strands.models import BedrockModel\n",
        "from strands.multiagent import Swarm\n",
        "import json\n",
        "import logging\n",
        "import boto3\n",
        "from ddgs import DDGS\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Configure logging\n",
        "logging.getLogger(\"strands.multiagent\").setLevel(logging.INFO)\n",
        "logging.basicConfig(format='%(levelname)s | %(name)s | %(message)s', handlers=[logging.StreamHandler()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIOFCcwGTZdB"
      },
      "source": [
        "## 4. LLM Invoke Function\n",
        "Create a function to invoke Bedrock and parse the LLM output as json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkVBb9aITZdC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "bedrock_client = boto3.client(\"bedrock-runtime\")\n",
        "\n",
        "def extract_json_from_text(text: str):\n",
        "    \"\"\"Extract JSON from LLM response that may contain markdown or extra text.\"\"\"\n",
        "    # Try to find JSON or list of JSON objects\n",
        "    json_match = re.search(r'(\\{.*\\}|\\[.*\\])', text, re.DOTALL)\n",
        "    if json_match:\n",
        "        json_str = json_match.group(1)\n",
        "        return json_str\n",
        "\n",
        "    return text\n",
        "\n",
        "def invoke_llm(prompt: str, model_id: str = \"us.anthropic.claude-sonnet-4-20250514-v1:0\", return_json: bool = True):\n",
        "    \"\"\"Invoke AWS Bedrock LLM with robust JSON extraction.\"\"\"\n",
        "    print(f'\\nðŸ¤– Invoking LLM for: {prompt[:80]}...')\n",
        "    try:\n",
        "        response = bedrock_client.invoke_model(\n",
        "            modelId=model_id,\n",
        "            contentType='application/json',\n",
        "            accept='application/json',\n",
        "            body=json.dumps({\n",
        "                'messages': [{'role': 'user', 'content': prompt}],\n",
        "                'max_tokens': 4096,\n",
        "                'anthropic_version': 'bedrock-2023-05-31'\n",
        "            })\n",
        "        )\n",
        "        result = json.loads(response.get('body').read())\n",
        "        llm_output = result['content'][0]['text']\n",
        "        print(f'âœ… LLM response received.')\n",
        "\n",
        "        if return_json:\n",
        "            # Extract and parse JSON\n",
        "            json_text = extract_json_from_text(llm_output)\n",
        "            try:\n",
        "                return json.loads(json_text)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f'âš ï¸ JSON parsing failed, returning raw text. Error: {e}')\n",
        "                return {\"error\": \"JSON parsing failed\", \"raw_response\": llm_output}\n",
        "        else:\n",
        "            return llm_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'âŒ Error invoking LLM: {e}')\n",
        "        return {\"error\": f\"LLM invocation failed: {str(e)}\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4NKfb6wTZdC"
      },
      "source": [
        "## 4. Define Tools for Each Agent\n",
        "\n",
        "Each agent needs specialized tools to perform its tasks. Let's define them using the `@tool` decorator.\n",
        "\n",
        "### File write and read tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Universal save_output tool for all agents\n",
        "@tool\n",
        "def save_output(agent_name: str, content: str, stage: str = \"output\") -> dict:\n",
        "    \"\"\"\n",
        "    Saves agent output to a markdown file for debugging and tracking.\n",
        "\n",
        "    Args:\n",
        "        agent_name: Name of the agent saving the output\n",
        "        content: The content to save\n",
        "        stage: Stage description (e.g., \"plan\", \"research\", \"analysis\", \"draft\", \"final\")\n",
        "\n",
        "    Returns:\n",
        "        dict with status and filename\n",
        "    \"\"\"\n",
        "    import os\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Create outputs directory if it doesn't exist\n",
        "    os.makedirs('agent_outputs', exist_ok=True)\n",
        "\n",
        "    # Generate filename with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"agent_outputs/{agent_name}_{stage}_{timestamp}.md\"\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"# {agent_name.replace('_', ' ').title()} - {stage.title()}\\n\\n\")\n",
        "            f.write(f\"**Timestamp:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "            f.write(\"---\\n\\n\")\n",
        "            f.write(content)\n",
        "\n",
        "        print(f\"ðŸ’¾ {agent_name} saved output to: {filename}\")\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"filename\": filename,\n",
        "            \"size\": len(content)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to save output: {e}\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "# Shared document tools for Writing and Critic agents\n",
        "@tool\n",
        "def append_to_report(section_title: str, content: str) -> dict:\n",
        "    \"\"\"\n",
        "    Appends a section to the shared DEEP_RESEARCH_REPORT.md file.\n",
        "    Used by Writing Agent to build the report section by section.\n",
        "\n",
        "    Args:\n",
        "        section_title: Title of the section being added\n",
        "        content: The content to append\n",
        "\n",
        "    Returns:\n",
        "        dict with status and current file size\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    filename = \"DEEP_RESEARCH_REPORT.md\"\n",
        "\n",
        "    try:\n",
        "        # Check if file exists to determine if we need a header\n",
        "        is_new_file = not os.path.exists(filename)\n",
        "\n",
        "        with open(filename, 'a', encoding='utf-8') as f:\n",
        "            if is_new_file:\n",
        "                # Add document header for new file\n",
        "                f.write(\"# Deep Research Report\\n\\n\")\n",
        "                f.write(\"*Generated by Multi-Agent Research Assistant*\\n\\n\")\n",
        "                f.write(\"---\\n\\n\")\n",
        "\n",
        "            # Append the section\n",
        "            f.write(f\"## {section_title}\\n\\n\")\n",
        "            f.write(content)\n",
        "            f.write(\"\\n\\n\")\n",
        "\n",
        "        # Get current file size\n",
        "        file_size = os.path.getsize(filename)\n",
        "\n",
        "        print(f\"ðŸ“ Appended '{section_title}' to {filename} (total size: {file_size} bytes)\")\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"filename\": filename,\n",
        "            \"section\": section_title,\n",
        "            \"total_size\": file_size\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to append to report: {e}\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "@tool\n",
        "def read_report() -> str:\n",
        "    \"\"\"\n",
        "    Reads the complete DEEP_RESEARCH_REPORT.md file and returns the content as a string.\n",
        "    Used by Critic Agent to review the full report.\n",
        "\n",
        "    Returns:\n",
        "        str: The complete report content, or error message if file doesn't exist\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    filename = \"DEEP_RESEARCH_REPORT.md\"\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(filename):\n",
        "            error_msg = f\"ERROR: Report file '{filename}' does not exist yet. Writing agent may not have completed.\"\n",
        "            print(f\"âŒ {error_msg}\")\n",
        "            return error_msg\n",
        "\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        file_size = os.path.getsize(filename)\n",
        "        word_count = len(content.split())\n",
        "        line_count = len(content.split('\\n'))\n",
        "\n",
        "        print(f\"ðŸ“– Read {filename} ({file_size} bytes, {word_count} words, {line_count} lines)\")\n",
        "\n",
        "        # Return just the content as a string - this avoids Bedrock parsing issues\n",
        "        return content\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"ERROR: Failed to read report: {str(e)}\"\n",
        "        print(f\"âŒ {error_msg}\")\n",
        "        return error_msg"
      ],
      "metadata": {
        "id": "Ql_ZpUtp9OMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Planning Agent Tools\n",
        "\n",
        "\n",
        "*   topic_analyzer: Analyzes a research topic to identify key concepts, scope, and complexity\n",
        "*   research_planner: Creates a structured research plan with subtopics and research questions.\n",
        "*   outline_generator: Generates a preliminary outline for the research report.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CuRUHwEg9Vxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSfsHIoPTZdC"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def topic_analyzer(topic: str) -> dict:\n",
        "    \"\"\"Analyzes a research topic to identify key concepts, scope, and complexity.\"\"\"\n",
        "    print(f'\\nðŸ” Analyzing topic: {topic}')\n",
        "    prompt = f\"\"\"Analyze the research topic: \"{topic}\"\n",
        "    Identify:\n",
        "    1. Key concepts (3-5 main concepts)\n",
        "    2. Scope (narrow/broad/comprehensive)\n",
        "    3. Complexity level (beginner/intermediate/advanced)\n",
        "    4. Research areas (3-5 primary areas to investigate)\n",
        "\n",
        "    Return your analysis as a JSON object with this exact structure:\n",
        "    {{\n",
        "      \"key_concepts\": [\"concept1\", \"concept2\", \"concept3\"],\n",
        "      \"scope\": \"comprehensive\",\n",
        "      \"complexity_level\": \"intermediate\",\n",
        "      \"research_areas\": [\"area1\", \"area2\", \"area3\", \"area4\"]\n",
        "    }}\n",
        "\n",
        "    Return ONLY the JSON object, no additional text.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=True)\n",
        "\n",
        "@tool\n",
        "def research_planner(topic: str, key_concepts: list) -> dict:\n",
        "    \"\"\"Creates a structured research plan with subtopics and research questions.\"\"\"\n",
        "    print(f'\\nðŸ“‹ Creating research plan for: {topic}')\n",
        "    prompt = f\"\"\"Create a structured research plan for: \"{topic}\"\n",
        "    Key concepts: {key_concepts}\n",
        "\n",
        "    Generate:\n",
        "    1. Subtopics (3-5 specific subtopics to explore)\n",
        "    2. Research questions (3-5 specific questions to answer)\n",
        "    3. Methodology (brief description of research approach)\n",
        "\n",
        "    Return your plan as a JSON object with this exact structure:\n",
        "    {{\n",
        "      \"subtopics\": [\"subtopic1\", \"subtopic2\", \"subtopic3\", \"subtopic4\"],\n",
        "      \"research_questions\": [\"question1\", \"question2\", \"question3\", \"question4\", \"question5\"],\n",
        "      \"methodology\": \"description of research approach\"\n",
        "    }}\n",
        "\n",
        "    Return ONLY the JSON object, no additional text.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=True)\n",
        "\n",
        "@tool\n",
        "def outline_generator(research_plan: dict) -> str:\n",
        "    \"\"\"Generates a preliminary outline for the research report.\"\"\"\n",
        "    print('\\nðŸ“ Generating report outline')\n",
        "    prompt = f\"\"\"Generate a detailed markdown outline for a research report based on this plan:\n",
        "    {json.dumps(research_plan, indent=2)}\n",
        "\n",
        "    Include these sections:\n",
        "    1. Executive Summary\n",
        "    2. Introduction\n",
        "    3. Methodology\n",
        "    4. Key Findings (with subsections for each subtopic from the plan)\n",
        "    5. Analysis and Discussion\n",
        "    6. Conclusions\n",
        "    7. References\n",
        "\n",
        "    Format the outline in markdown with proper heading levels (##, ###).\n",
        "    Return ONLY the markdown outline, no additional commentary.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_analyzer(\"AI impact for workforce: future direction\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amKcZoYFD2ZL",
        "outputId": "a5f1637f-43f8-4046-f4b2-f5687a99a265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Analyzing topic: AI impact for workforce: future direction\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Analyze the research topic: \"AI impact for workforce: future direction\"\n",
            "    Iden...\n",
            "âœ… LLM response received.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'key_concepts': ['Artificial Intelligence',\n",
              "  'Workforce Transformation',\n",
              "  'Job Displacement and Creation',\n",
              "  'Skills Evolution',\n",
              "  'Future of Work'],\n",
              " 'scope': 'comprehensive',\n",
              " 'complexity_level': 'intermediate',\n",
              " 'research_areas': ['AI Automation and Job Market Effects',\n",
              "  'Reskilling and Workforce Development',\n",
              "  'Human-AI Collaboration Models',\n",
              "  'Economic and Social Policy Implications']}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AB9h5AtTZdD"
      },
      "source": [
        "### Research Agent Tools\n",
        "\n",
        "\n",
        "*   web_search: Performs web search to find relevant information and sources.\n",
        "*   content_extractor: Extracts and summarizes key information from a web source.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhHELSXJTZdD"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def web_search(query: str, num_results: int = 5) -> list:\n",
        "    \"\"\"Performs web search to find relevant information and sources.\"\"\"\n",
        "    print(f'\\nðŸ”Ž Searching web for: {query}')\n",
        "    try:\n",
        "        with DDGS() as ddgs:\n",
        "            results = [r for r in ddgs.text(query, max_results=num_results)]\n",
        "        print(f'âœ… Found {len(results)} results.')\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f'âŒ Web search failed: {e}')\n",
        "        return []\n",
        "\n",
        "\n",
        "@tool\n",
        "def content_extractor(url: str) -> dict:\n",
        "    \"\"\"Extracts and summarizes key information from a web source.\"\"\"\n",
        "    print(f'\\nðŸ“„ Extracting content from: {url}')\n",
        "\n",
        "    if url.endswith(\".pdf\"):\n",
        "        return {\n",
        "                    'error': str('pdf file'),\n",
        "                    'url': url,\n",
        "                    'summary': f'Could not parse pdf',\n",
        "                    'key_points': ['Cannot parse pdf, skip']\n",
        "                }\n",
        "\n",
        "    # Try multiple times with increasing timeouts\n",
        "    timeouts = [10, 20]\n",
        "\n",
        "    for attempt, timeout in enumerate(timeouts, 1):\n",
        "        try:\n",
        "            print(f'  Attempt {attempt}/{len(timeouts)} (timeout: {timeout}s)...')\n",
        "\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "                'Accept-Language': 'en-US,en;q=0.5',\n",
        "                'Accept-Encoding': 'gzip, deflate',\n",
        "                'Connection': 'keep-alive',\n",
        "            }\n",
        "\n",
        "            response = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse content\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Remove script and style elements\n",
        "            for script in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\"]):\n",
        "                script.decompose()\n",
        "\n",
        "            # Extract text from paragraphs first\n",
        "            paragraphs = soup.find_all('p')\n",
        "            text = ' '.join(p.get_text().strip() for p in paragraphs if p.get_text().strip())\n",
        "\n",
        "            # Fallback to all text if no paragraphs\n",
        "            if not text or len(text) < 100:\n",
        "                text = soup.get_text(separator=' ', strip=True)\n",
        "\n",
        "            # Clean up whitespace\n",
        "            text = ' '.join(text.split())\n",
        "\n",
        "            # Limit text length\n",
        "            text = text[:10000]\n",
        "\n",
        "            if not text or len(text) < 50:\n",
        "                return {\n",
        "                    'error': 'No meaningful content extracted',\n",
        "                    'url': url,\n",
        "                    'summary': 'Content extraction failed - page may be empty or require JavaScript',\n",
        "                    'key_points': []\n",
        "                }\n",
        "\n",
        "            print(f'  âœ… Content extracted ({len(text)} chars)')\n",
        "\n",
        "            # Use LLM to summarize\n",
        "            prompt = f\"\"\"Summarize the following web content and extract the top 5 key points.\n",
        "                      Content from {url}:\n",
        "                      {text}\n",
        "                      Return a JSON object with this exact structure:\n",
        "                      {{\n",
        "                        \"summary\": \"brief summary of the content (2-3 sentences)\",\n",
        "                        \"key_points\": [\"point1\", \"point2\", \"point3\", \"point4\", \"point5\"]\n",
        "                      }}\n",
        "                      Return ONLY the JSON object, no additional text.\"\"\"\n",
        "\n",
        "            result = invoke_llm(prompt, return_json=True)\n",
        "\n",
        "            # Add URL and metadata\n",
        "            if isinstance(result, dict) and 'error' not in result:\n",
        "                result['url'] = url\n",
        "                result['content_length'] = len(text)\n",
        "                return result\n",
        "            else:\n",
        "                return {'error': 'LLM summarization failed', 'url': url, 'raw_result': result}\n",
        "\n",
        "        except requests.exceptions.Timeout:\n",
        "            print(f'  â±ï¸ Timeout after {timeout}s')\n",
        "            if attempt == len(timeouts):\n",
        "                # Last attempt failed\n",
        "                return {\n",
        "                    'error': f'Timeout after {len(timeouts)} attempts',\n",
        "                    'url': url,\n",
        "                    'summary': f'Could not extract content - website took longer than {timeouts[-1]} seconds to respond',\n",
        "                    'key_points': ['Content extraction timed out', 'Website may be slow or unavailable']\n",
        "                }\n",
        "            # Try again with longer timeout\n",
        "            continue\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f'  âŒ Request failed: {e}')\n",
        "            return {\n",
        "                'error': str(e),\n",
        "                'url': url,\n",
        "                'summary': f'Could not access website: {str(e)}',\n",
        "                'key_points': ['Website access failed', 'May be blocked or unavailable']\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'  âŒ Unexpected error: {e}')\n",
        "            return {\n",
        "                'error': str(e),\n",
        "                'url': url,\n",
        "                'summary': f'Content extraction failed: {str(e)}',\n",
        "                'key_points': ['Extraction error occurred']\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_search(\"Top AI impact for workforce\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adyrNS2kGom9",
        "outputId": "182646e4-110f-45e6-9340-d383056a538c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”Ž Searching web for: Top AI impact for workforce\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:primp.impersonate:Impersonate 'chrome_120' does not exist, using 'random'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found 5 results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'How artificial intelligence impacts the US labor market | MIT Sloan',\n",
              "  'href': 'https://mitsloan.mit.edu/ideas-made-to-matter/how-artificial-intelligence-impacts-us-labor-market',\n",
              "  'body': 'October 9, 2025 - Thatâ€™s because AI boosted firm productivity : Companies that used the technology grew faster, which helped sustain or even expand head count in high-exposure positions. The takeaway for employers rolling the technology out to their workforce: ...'},\n",
              " {'title': 'Evaluating the Impact of AI on the Labor Market: Current State of Affairs | The Budget Lab at Yale',\n",
              "  'href': 'https://budgetlab.yale.edu/research/evaluating-impact-ai-labor-market-current-state-affairs',\n",
              "  'body': 'As such, this metric attempts to capture how different the sum of occupations that make up the labor force is relative to another point in time. By measuring this over the time generative AI has been publicly available, we can test the claim that AI is substantially changing the workforce by any of the methods mentioned above (pushing workers from one job to another, automating workers out of a job, or creating new jobs).'},\n",
              " {'title': 'How will Artificial Intelligence Affect Jobs 2026-2030 | Nexford University',\n",
              "  'href': 'https://www.nexford.edu/insights/how-will-ai-affect-jobs',\n",
              "  'body': '3 weeks ago - Researchers from the University of Pennsylvania and OpenAI found some educated white-collar workers earning up to $80,000 a year are the most likely to be affected by workforce automation.'},\n",
              " {'title': 'How Will AI Affect the Global Workforce? | Goldman Sachs',\n",
              "  'href': 'https://www.goldmansachs.com/insights/articles/how-will-ai-affect-the-global-workforce',\n",
              "  'body': 'August 13, 2025 - Unemployment among 20- to 30-year-olds in tech-exposed occupations has risen by almost 3 percentage points since the start of 2025 , notably higher than for their same-aged counterparts in other trades and for overall tech workers as well.'},\n",
              " {'title': 'Educating a future workforce that will match AI disruption | World Economic Forum',\n",
              "  'href': 'https://www.weforum.org/stories/2025/10/education-disruptive-ai-workforce-opportunities/',\n",
              "  'body': 'Todayâ€™s baseline workforce, composed largely of general-purpose software developers, data analysts and IT support professionals, will likely face fundamental disruptions as routine coding and traditional IT tasks become fully automated. AI systems are already on course to autonomously generate, test and deploy solutions, reducing repetitive human tasks. But this disruption will unlock new opportunities. The demand for roles that combine domain-specific expertise with AI literacy â€“ including AI system architects, ethics and governance specialists, human-AI collaboration designers, and physical AI specialists working in robotics and autonomous mobility â€“ will significantly increase.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content_extractor('https://www.deloitte.com/us/en/services/consulting/services/humans-x-machines.html')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myX7l3WlGWML",
        "outputId": "8ab444fc-1927-434f-f382-9a084c83f163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“„ Extracting content from: https://www.deloitte.com/us/en/services/consulting/services/humans-x-machines.html\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (5867 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': \"Deloitte's Humans x Machines service helps organizations combine human and AI capabilities to create exponential value through intentional work design. The approach focuses on leveraging the strengths of both humans and machines while building trust, measuring impact, and transforming work processes across industries.\",\n",
              " 'key_points': [\"Workers are 5.2x more likely to champion AI tools when trust in employer's GenAI is high, emphasizing the critical role of trust in AI adoption\",\n",
              "  'Success requires intentional work design that combines human ingenuity with AI capabilities, moving beyond simple human-plus-machine to human-times-machine multiplication',\n",
              "  'Deloitte offers comprehensive solutions including Workforce Impacts analysis, AI Integration Studio, and Human Capital AI Solution Suite to assess and implement human-machine collaboration',\n",
              "  'The approach spans end-to-end transformation from strategy to execution, covering front-line operations, back office functions, and HR processes with industry-specific knowledge',\n",
              "  'Solutions focus on measuring and closing trust gaps, designing human-centered AI adoption, and architecting resilient organizational structures that adapt to continuous change'],\n",
              " 'url': 'https://www.deloitte.com/us/en/services/consulting/services/humans-x-machines.html',\n",
              " 'content_length': 5867}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qidNr1jPTZdD"
      },
      "source": [
        "### Analysis Agent Tools\n",
        "\n",
        "\n",
        "*   insight_extractor: Extracts key insights and findings from the input data.\n",
        "*   theme_organizer: Organizes findings into logical themes and categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOeMXA37TZdD"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def insight_extractor(input_data: str) -> list:\n",
        "    \"\"\"Extracts key insights and findings from the input data.\"\"\"\n",
        "    print('\\nðŸ’¡ Extracting key insights')\n",
        "    prompt = f\"\"\"From the input data, extract the top 3-5 most critical insights.\n",
        "\n",
        "    Input data:\n",
        "    {input_data[:10000]}\n",
        "\n",
        "    For each insight provide:\n",
        "    1. The insight itself\n",
        "    2. Supporting evidence\n",
        "    3. Significance level (High/Medium/Low)\n",
        "\n",
        "    Return a JSON array with this exact structure:\n",
        "    [\n",
        "      {{\n",
        "        \"insight\": \"description of insight\",\n",
        "        \"evidence\": \"supporting evidence\",\n",
        "        \"significance\": \"High\"\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    Return ONLY the JSON array, no additional text.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=True)\n",
        "\n",
        "@tool\n",
        "def theme_organizer(insights: list) -> dict:\n",
        "    \"\"\"Organizes findings into logical themes and categories.\"\"\"\n",
        "    print('\\nðŸ—‚ï¸ Organizing themes')\n",
        "    prompt = f\"\"\"Organize these insights into 2-3 main themes for a research report.\n",
        "\n",
        "    Insights:\n",
        "    {json.dumps(insights, indent=2)}\n",
        "\n",
        "    Return a JSON object where each key is a theme name and value contains:\n",
        "    - description: brief description of the theme\n",
        "    - insights: list of relevant insights from the input\n",
        "\n",
        "    Structure:\n",
        "    {{\n",
        "      \"Theme Name 1\": {{\n",
        "        \"description\": \"theme description\",\n",
        "        \"insights\": [\"insight1\", \"insight2\"]\n",
        "      }},\n",
        "      \"Theme Name 2\": {{\n",
        "        \"description\": \"theme description\",\n",
        "        \"insights\": [\"insight3\", \"insight4\"]\n",
        "      }}\n",
        "    }}\n",
        "\n",
        "    Return ONLY the JSON object, no additional text.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euz_e6j-TZdD"
      },
      "source": [
        "### Writing Agent Tools\n",
        "\n",
        "\n",
        "*   content_writer: Writes well-structured research content based on section and data.\n",
        "*   citation_manager: Adds proper citations and manages references.\n",
        "*   section_formatter: Formats sections according to research report standards.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rktFDGlnTZdD"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def content_writer(section: str, content_data: str) -> str:\n",
        "    \"\"\"Writes well-structured research content based on section and data.\"\"\"\n",
        "    print(f'\\nâœï¸ Writing {section} section')\n",
        "    prompt = f\"\"\"Write a comprehensive, well-structured section for a research report.\n",
        "\n",
        "    Section: {section}\n",
        "    Data to include:\n",
        "    {content_data}\n",
        "\n",
        "    Requirements:\n",
        "    - Academic and objective tone\n",
        "    - Well-organized paragraphs\n",
        "    - Use markdown formatting\n",
        "    - Include relevant details from the data\n",
        "\n",
        "    Return ONLY the written content in markdown format, no additional commentary.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=False)\n",
        "\n",
        "\n",
        "@tool\n",
        "def citation_manager(content: str, sources: list) -> str:\n",
        "    \"\"\"Adds proper citations and manages references.\"\"\"\n",
        "    print('\\nðŸ“š Adding citations...')\n",
        "    cited_content = content\n",
        "    reference_list = '\\n\\n## References\\n\\n'\n",
        "\n",
        "    if not sources:\n",
        "        return content\n",
        "\n",
        "    for i, source in enumerate(sources, 1):\n",
        "        if isinstance(source, dict) and 'url' in source:\n",
        "            cited_content += f' [{i}]'\n",
        "            title = source.get('title', 'Source')\n",
        "            url = source.get('url', '')\n",
        "            reference_list += f\"{i}. {title} - <{url}>\\n\"\n",
        "\n",
        "    return cited_content + reference_list\n",
        "\n",
        "\n",
        "@tool\n",
        "def section_formatter(content: str, section_type: str) -> str:\n",
        "    \"\"\"Formats sections according to research report standards.\"\"\"\n",
        "    print(f'\\nðŸ“ Formatting {section_type} section...')\n",
        "    return f'\\n---\\n{content}\\n---\\n'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Q1j4c-TZdD"
      },
      "source": [
        "### Critic Agent Tools\n",
        "\n",
        "\n",
        "*   quality_checker: Evaluates report quality, completeness, and coherence.\n",
        "*   improvement_suggester: Suggests specific improvements and refinements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxoUajiUTZdD"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def quality_checker(report: str) -> dict:\n",
        "    \"\"\"Evaluates report quality, completeness, and coherence.\"\"\"\n",
        "    print('\\nðŸ” Checking report quality')\n",
        "    prompt = f\"\"\"Evaluate this research report for quality, completeness, and coherence.\n",
        "\n",
        "    Report:\n",
        "    {report[:10000]}\n",
        "\n",
        "    Provide:\n",
        "    1. Quality score (0.0 to 1.0)\n",
        "    2. Completeness score (0.0 to 1.0)\n",
        "    3. Coherence score (0.0 to 1.0)\n",
        "    4. Strengths (list of 2-4 strengths)\n",
        "    5. Weaknesses (list of 2-4 weaknesses)\n",
        "\n",
        "    Return a JSON object with this exact structure:\n",
        "    {{\n",
        "      \"quality_score\": 0.85,\n",
        "      \"completeness_score\": 0.90,\n",
        "      \"coherence_score\": 0.88,\n",
        "      \"strengths\": [\"strength1\", \"strength2\"],\n",
        "      \"weaknesses\": [\"weakness1\", \"weakness2\"]\n",
        "    }}\n",
        "\n",
        "    Return ONLY the JSON object, no additional text.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=True)\n",
        "\n",
        "\n",
        "@tool\n",
        "def improvement_suggester(report: str, quality_assessment: dict) -> list:\n",
        "    \"\"\"Suggests specific improvements and refinements.\"\"\"\n",
        "    print('\\nðŸ’¡ Generating improvement suggestions')\n",
        "    prompt = f\"\"\"Based on this quality assessment, provide specific, actionable suggestions to improve the report.\n",
        "\n",
        "    Quality Assessment:\n",
        "    {json.dumps(quality_assessment, indent=2)}\n",
        "\n",
        "    For each suggestion provide:\n",
        "    1. Priority (High/Medium/Low)\n",
        "    2. Category (Content/Structure/Clarity)\n",
        "    3. The suggestion itself\n",
        "\n",
        "    Return a JSON array with this exact structure:\n",
        "    [\n",
        "      {{\n",
        "        \"priority\": \"High\",\n",
        "        \"category\": \"Content\",\n",
        "        \"suggestion\": \"specific actionable suggestion\"\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    Return ONLY the JSON array, no additional text.\"\"\"\n",
        "\n",
        "    return invoke_llm(prompt, return_json=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-g7MLR_TZdE"
      },
      "source": [
        "## 5. Create the Specialized Agents\n",
        "\n",
        "Now we'll create our five specialized agents, each with their own system prompt and tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCgBm5A0TZdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1c0c4a-0c7a-4260-a45b-062ed442d85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All agents created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Configure the Bedrock model\n",
        "bedrock_model = BedrockModel(\n",
        "    model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
        "    region_name=\"us-east-1\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Planning Agent\n",
        "planning_agent = Agent(\n",
        "    name=\"planning_agent\",\n",
        "    system_prompt=\"\"\"\n",
        "      You are a research planning specialist. Your role is to:\n",
        "      1. Analyze research topics to identify key concepts and scope\n",
        "      2. Create structured research plans with subtopics and questions\n",
        "      3. Generate preliminary outlines for research reports\n",
        "\n",
        "      After completing your planning work:\n",
        "      1. Use save_output to save your research plan and outline\n",
        "      2. Hand off to the research_agent to begin information gathering\n",
        "      Use your tools to thoroughly analyze and plan before handing off.\n",
        "      \"\"\",\n",
        "    tools=[topic_analyzer, research_planner, outline_generator, save_output],\n",
        "    model=bedrock_model\n",
        ")\n",
        "\n",
        "# Research Agent\n",
        "research_agent = Agent(\n",
        "    name=\"research_agent\",\n",
        "    system_prompt=\"\"\"\n",
        "      You are a research specialist focused on gathering comprehensive information. Your role is to:\n",
        "      1. Search for relevant information using web_search\n",
        "      2. Extract key content from sources using content_extractor\n",
        "\n",
        "      Gather information on all subtopics from the research plan. Once you have sufficient\n",
        "      high-quality information:\n",
        "      1. Use save_output to save all gathered research data and sources\n",
        "      2. Hand off to the analysis_agent for synthesis\n",
        "      \"\"\",\n",
        "    tools=[web_search, content_extractor, save_output],\n",
        "    model=bedrock_model\n",
        ")\n",
        "\n",
        "# Analysis Agent\n",
        "analysis_agent = Agent(\n",
        "    name=\"analysis_agent\",\n",
        "    system_prompt=\"\"\"\n",
        "      You are an analytical specialist who synthesizes research findings. Your role is to:\n",
        "      1. Extract key insights using insight_extractor\n",
        "      2. Organize findings into logical themes using theme_organizer\n",
        "\n",
        "      Thoroughly analyze all gathered information and organize it logically. When analysis is\n",
        "      complete:\n",
        "      1. Use save_output to save your analysis, insights, and organized themes\n",
        "      2. Hand off to the writing_agent to create the report\n",
        "      \"\"\",\n",
        "    tools=[insight_extractor, theme_organizer, save_output],\n",
        "    model=bedrock_model\n",
        ")\n",
        "\n",
        "# Writing Agent\n",
        "writing_agent = Agent(\n",
        "    name=\"writing_agent\",\n",
        "    system_prompt=\"\"\"\n",
        "      You are a professional research writer who creates well-structured reports. Your role is\n",
        "      Create a complete research report based on the analysis. Write each section carefully with\n",
        "      proper structure and citations:\n",
        "      1. Write clear, comprehensive content using content_writer for each section\n",
        "      2. Add proper citations using citation_manager\n",
        "      3. Format sections professionally using section_formatter\n",
        "      4. Append each completed section to DEEP_RESEARCH_REPORT.md using append_to_report\n",
        "\n",
        "      IMPORTANT:\n",
        "      - Build the report section by section, appending each one to DEEP_RESEARCH_REPORT.md\n",
        "      - Hand off to the critic_agent for review\n",
        "      - The critic will read the complete report from DEEP_RESEARCH_REPORT.md\n",
        "\n",
        "      Do NOT output the full report in your response - it's being built in the file.\n",
        "      Just confirm completion and hand off to critic_agent.\n",
        "      \"\"\",\n",
        "    tools=[content_writer, citation_manager, section_formatter, append_to_report],\n",
        "    model=bedrock_model\n",
        ")\n",
        "\n",
        "# Critic Agent\n",
        "critic_agent = Agent(\n",
        "    name=\"critic_agent\",\n",
        "    system_prompt=\"\"\"\n",
        "      You are a critical reviewer and quality assurance specialist. Your role is to:\n",
        "      1. Read the complete report from DEEP_RESEARCH_REPORT.md using read_report\n",
        "      2. Evaluate report quality using quality_checker\n",
        "      3. Suggest improvements using improvement_suggester\n",
        "      4. If there are major issues (quality score < 0.8):\n",
        "        - Hand back to writing_agent for content issues\n",
        "        - Hand back to research_agent for missing information\n",
        "      5. If the report meets quality standards (score >= 0.8):\n",
        "        - Use save_output to save your assessment\n",
        "\n",
        "      Provide your final assessment in this format:\n",
        "      ---\n",
        "      ## Quality Assessment\n",
        "\n",
        "      **Report File:** DEEP_RESEARCH_REPORT.md\n",
        "\n",
        "      **Quality Score:** [score]\n",
        "      **Completeness Score:** [score]\n",
        "      **Coherence Score:** [score]\n",
        "\n",
        "      ### Strengths\n",
        "      - [strength 1]\n",
        "      - [strength 2]\n",
        "      - [strength 3]\n",
        "\n",
        "      ### Areas for Improvement\n",
        "      - [suggestion 1]\n",
        "      - [suggestion 2]\n",
        "\n",
        "      ### Verdict\n",
        "      [APPROVED / NEEDS REVISION]\n",
        "\n",
        "      ---\n",
        "\n",
        "      IMPORTANT:\n",
        "      - Read the report from DEEP_RESEARCH_REPORT.md, don't expect it in the handoff message\n",
        "      - The complete report is in the file, not in your context\n",
        "      - Your assessment should reference the file content\n",
        "      - Do not hand off after approval - this is the final step\n",
        "      \"\"\",\n",
        "          tools=[read_report, quality_checker, improvement_suggester, save_output],\n",
        "          model=bedrock_model\n",
        ")\n",
        "\n",
        "print(\"âœ… All agents created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNuDXBF4TZdE"
      },
      "source": [
        "## 6. Create and Configure the Swarm\n",
        "\n",
        "Now we'll create the Swarm that orchestrates our multi-agent system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWAy0861TZdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b74fcdd-67af-4995-80dc-a67603516152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Swarm created successfully!\n",
            "\n",
            "Swarm Configuration:\n",
            "  - Entry point: planning_agent\n",
            "  - Number of agents: 5\n",
            "  - Max handoffs: 25\n",
            "  - Max iterations: 30\n"
          ]
        }
      ],
      "source": [
        "# Create the swarm with all agents\n",
        "research_swarm = Swarm(\n",
        "    [\n",
        "        planning_agent,\n",
        "        research_agent,\n",
        "        analysis_agent,\n",
        "        writing_agent,\n",
        "        critic_agent\n",
        "    ],\n",
        "    entry_point=planning_agent,  # Start with planning\n",
        "    max_handoffs=25,  # Allow sufficient handoffs for collaboration\n",
        "    max_iterations=30,  # Total iterations across all agents\n",
        "    execution_timeout=1800.0,  # 30 minutes for complex research\n",
        "    node_timeout=600.0,  # 10 minutes per agent\n",
        "    repetitive_handoff_detection_window=8,\n",
        "    repetitive_handoff_min_unique_agents=3\n",
        ")\n",
        "\n",
        "print(\"âœ… Swarm created successfully!\")\n",
        "print(f\"\\nSwarm Configuration:\")\n",
        "print(f\"  - Entry point: {planning_agent.name}\")\n",
        "print(f\"  - Number of agents: 5\")\n",
        "print(f\"  - Max handoffs: 25\")\n",
        "print(f\"  - Max iterations: 30\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axQIFjK4TZdE"
      },
      "source": [
        "## 7. Execute the Research Swarm\n",
        "\n",
        "Let's run our multi-agent system on a research topic!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3PWZv4ETZdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b881aea4-97b4-46dc-f1b4-d2f1760ef27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING MULTI-AGENT DEEP RESEARCH\n",
            "================================================================================\n",
            "\n",
            "Topic: The impact of artificial intelligence on workforce: future directions\n",
            "\n",
            "The agents will now collaborate to produce a comprehensive research report...\n",
            "\n",
            "================================================================================\n",
            "\n",
            "I'll help you create a comprehensive research plan for \"The impact of artificial intelligence on workforce: future directions.\" Let me start by analyzing this topic to identify key concepts and scope.\n",
            "Tool #1: topic_analyzer\n",
            "\n",
            "ðŸ” Analyzing topic: The impact of artificial intelligence on workforce: future directions\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Analyze the research topic: \"The impact of artificial intelligence on workforce:...\n",
            "âœ… LLM response received.\n",
            "Now I'll create a structured research plan based on these key concepts:\n",
            "Tool #2: research_planner\n",
            "\n",
            "ðŸ“‹ Creating research plan for: The impact of artificial intelligence on workforce: future directions\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Create a structured research plan for: \"The impact of artificial intelligence on...\n",
            "âœ… LLM response received.\n",
            "Now let me generate a preliminary outline for the research report:\n",
            "Tool #3: outline_generator\n",
            "\n",
            "ðŸ“ Generating report outline\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Generate a detailed markdown outline for a research report based on this plan:\n",
            " ...\n",
            "âœ… LLM response received.\n",
            "Now let me save this comprehensive research plan and outline:\n",
            "Tool #4: save_output\n",
            "ðŸ’¾ planning_agent saved output to: agent_outputs/planning_agent_plan_20260220_203025.md\n",
            "Perfect! I've completed a comprehensive research planning phase for your topic \"The impact of artificial intelligence on workforce: future directions.\" Here's what I've accomplished:\n",
            "\n",
            "## Research Plan Summary:\n",
            "\n",
            "**Topic Analysis**: Identified this as an intermediate complexity, comprehensive scope research topic with five key concepts ranging from AI technology to future labor market trends.\n",
            "\n",
            "**Research Structure**: Created four main subtopics:\n",
            "1. AI-driven job displacement patterns\n",
            "2. Emerging job roles and opportunities\n",
            "3. Evolution of skill requirements\n",
            "4. Economic and social implications\n",
            "\n",
            "**Research Questions**: Developed five focused research questions covering vulnerability factors, new opportunities, skill evolution, implementation timelines, and policy adaptation.\n",
            "\n",
            "**Methodology**: Designed a mixed-methods approach combining literature review, quantitative data analysis, case studies, expert interviews, and comparative analysis.\n",
            "\n",
            "**Report Outline**: Generated a detailed structure with 6 main sections and comprehensive subsections that will guide the research and writing process.\n",
            "\n",
            "Now I'll hand off to the research agent to begin gathering information based on this plan:\n",
            "Tool #5: handoff_to_agent\n",
            "The research planning phase is now complete! I've created a thorough foundation for your research project and handed it off to the research agent to begin gathering information. The research agent will now start collecting data, sources, and evidence based on the structured plan and methodology I've developed.I'll begin comprehensive information gathering on the impact of AI on the workforce, focusing on the four main subtopics identified in the research plan. Let me start by searching for information on each key area.\n",
            "Tool #1: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: AI artificial intelligence job displacement automation impact employment industries 2024 2025\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #2: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.nexford.edu/insights/how-will-ai-affect-jobs\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (10000 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #3: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5403661\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5403661\n",
            "\n",
            "Tool #4: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: emerging jobs created by AI integration new roles artificial intelligence workforce 2024\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #5: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.atera.com/blog/new-ai-job-roles/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://www.atera.com/blog/new-ai-job-roles/\n",
            "\n",
            "Tool #6: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.salesforce.com/blog/ai-jobs/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (10000 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #7: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.gartner.com/en/newsroom/press-releases/2024-05-14-artificial-intelligence-is-creating-new-roles-and-skills-in-data-and-analytics\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://www.gartner.com/en/newsroom/press-releases/2024-05-14-artificial-intelligence-is-creating-new-roles-and-skills-in-data-and-analytics\n",
            "\n",
            "Tool #8: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: AI skills requirements evolution reskilling upskilling workforce development 2024 future\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #9: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.weforum.org/publications/the-future-of-jobs-report-2025/in-full/3-skills-outlook/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://www.weforum.org/publications/the-future-of-jobs-report-2025/in-full/3-skills-outlook/\n",
            "\n",
            "Tool #10: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.ibm.com/think/insights/ai-upskilling\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (10000 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #11: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.mercer.com/en-sg/insights/talent-and-transformation/skill-based-talent-management/transformation-of-skill-needs-in-the-age-of-generative-ai/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (1440 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #12: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: economic social implications AI workforce transformation policy frameworks 2024 2025\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #13: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://socialfinance.org/insight/shaping-the-future-of-work-generative-ai-inequality-and-opportunity/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://socialfinance.org/insight/shaping-the-future-of-work-generative-ai-inequality-and-opportunity/\n",
            "\n",
            "Tool #14: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://time.com/7357476/economics-of-ai-and-jobs/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (7926 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #15: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: McKinsey Goldman Sachs AI workforce impact studies job displacement automation reports 2024\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #16: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.goldmansachs.com/insights/articles/how-will-ai-affect-the-global-workforce\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (8350 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #17: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: World Economic Forum Future of Jobs Report 2025 AI workforce transformation employment trends\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #18: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://blog.coursera.org/wef-future-of-jobs-report-2025/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (2440 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #19: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: \"AI human collaboration\" \"hybrid workforce\" models productivity enhancement 2024 2025\n",
            "âœ… Found 8 results.\n",
            "\n",
            "Tool #20: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âœ… Content extracted (7893 chars)\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Summarize the following web content and extract the top 5 key points.\n",
            "          ...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #21: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.gartner.com/en/articles/human-ai-collaboration\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://www.gartner.com/en/articles/human-ai-collaboration\n",
            "\n",
            "Tool #22: web_search\n",
            "\n",
            "ðŸ”Ž Searching web for: AI workforce policy frameworks government response regulation 2024 2025 labor protection\n",
            "âœ… Found 6 results.\n",
            "\n",
            "Tool #23: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://mostpolicyinitiative.org/science-note/state-regulation-of-ai-workforce/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
            "\n",
            "Tool #24: content_extractor\n",
            "\n",
            "ðŸ“„ Extracting content from: https://www.epi.org/publication/federal-ai-legislation/\n",
            "  Attempt 1/2 (timeout: 10s)...\n",
            "  âŒ Request failed: 403 Client Error: Forbidden for url: https://www.epi.org/publication/federal-ai-legislation/\n",
            "\n",
            "Tool #25: save_output\n",
            "ðŸ’¾ research_agent saved output to: agent_outputs/research_agent_research_20260220_203339.md\n",
            "\n",
            "Tool #26: handoff_to_agent\n",
            "I have successfully completed comprehensive information gathering on the impact of AI on the workforce. Here's what I accomplished:\n",
            "\n",
            "## Research Completed\n",
            "\n",
            "**Four Main Research Areas Covered:**\n",
            "1. **AI-driven job displacement patterns** - Analyzed displacement projections, vulnerable industries, and timeline estimates\n",
            "2. **Emerging job roles created by AI** - Identified new technical and strategic positions being created\n",
            "3. **Evolution of skill requirements** - Examined changing competency needs and reskilling imperatives  \n",
            "4. **Economic and social implications** - Explored productivity impacts, policy needs, and workforce transformation models\n",
            "\n",
            "## Key Research Findings\n",
            "\n",
            "- **Net Job Creation**: 92 million jobs displaced but 170 million new jobs created by 2030 (net gain of 78 million globally)\n",
            "- **Skills Transformation**: 39% of workers' core skills expected to change by 2030\n",
            "- **Productivity Gains**: 15% potential productivity increase from AI adoption\n",
            "- **Transition Timeline**: Historical patterns suggest 2-year resolution period for tech-driven displacement\n",
            "- **Critical Gap**: Only 6% of organizations have begun meaningful AI upskilling despite 89% recognizing the need\n",
            "\n",
            "## Sources and Data Quality\n",
            "\n",
            "Gathered information from authoritative sources including:\n",
            "- World Economic Forum Future of Jobs Report 2025\n",
            "- Goldman Sachs Research on AI workforce impact\n",
            "- McKinsey Global Institute projections\n",
            "- IBM AI upskilling insights\n",
            "- Salesforce workforce transformation analysis\n",
            "- Wharton/University of Pennsylvania hybrid intelligence research\n",
            "\n",
            "## Next Steps\n",
            "\n",
            "I've saved all research findings and handed off to the analysis_agent to:\n",
            "- Synthesize the gathered information\n",
            "- Analyze strategic implications\n",
            "- Develop insights on future workforce transformation directions\n",
            "- Examine policy and organizational recommendations\n",
            "\n",
            "The research provides a solid foundation for understanding both the challenges and opportunities that AI presents for the future workforce.I'll analyze the comprehensive research findings on AI's impact on the workforce and extract key insights, then organize them into logical themes for the final report.\n",
            "Tool #1: insight_extractor\n",
            "\n",
            "ðŸ’¡ Extracting key insights\n",
            "\n",
            "ðŸ¤– Invoking LLM for: From the input data, extract the top 3-5 most critical insights.\n",
            "\n",
            "    Input data...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #2: theme_organizer\n",
            "\n",
            "ðŸ—‚ï¸ Organizing themes\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Organize these insights into 2-3 main themes for a research report.\n",
            "\n",
            "    Insight...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #3: save_output\n",
            "ðŸ’¾ analysis_agent saved output to: agent_outputs/analysis_agent_analysis_20260220_203434.md\n",
            "\n",
            "Tool #4: handoff_to_agent\n",
            "I have successfully completed the analysis phase of the AI workforce impact research. Here's what I accomplished:\n",
            "\n",
            "## Key Analysis Results:\n",
            "\n",
            "**Five Critical Insights Extracted:**\n",
            "1. **Net Job Creation**: AI will create 78 million more jobs than it displaces by 2030, but requires massive workforce transformation\n",
            "2. **Skills Polarization**: Administrative/routine work faces displacement while creative and interpersonal roles gain value  \n",
            "3. **Investment Returns**: Corporate reskilling programs deliver exceptional 6x ROI\n",
            "4. **Inequality Risk**: AI could widen economic disparities without coordinated intervention\n",
            "5. **Hybrid Roles**: New positions combining AI technical skills with human capabilities are emerging\n",
            "\n",
            "**Three Strategic Themes Organized:**\n",
            "1. **Workforce Transformation and Skills Evolution** - The fundamental restructuring of job markets and skill requirements\n",
            "2. **Economic Inequality and Societal Impact** - Risks of exacerbating disparities and need for intervention strategies  \n",
            "3. **Corporate Adaptation and Investment Strategies** - Critical role of organizational investment in successful AI transition\n",
            "\n",
            "**Future Directions Framework:**\n",
            "- Short-term (1-2 years): Focus on reskilling programs and policy development\n",
            "- Medium-term (3-5 years): Deploy hybrid workforce models and educational pathways\n",
            "- Long-term (5-10 years): Full AI-human collaboration integration and mature policy frameworks\n",
            "\n",
            "The analysis has been saved and I've handed off to the writing agent to create the comprehensive final report. The research reveals a clear path forward that balances the tremendous opportunities AI creates with the need for proactive intervention to ensure equitable workforce transformation.I'll create a comprehensive research report based on the analysis findings. Let me build this report section by section, starting with the executive summary and working through each key theme.\n",
            "Tool #1: content_writer\n",
            "\n",
            "âœï¸ Writing Executive Summary section\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Write a comprehensive, well-structured section for a research report.\n",
            "\n",
            "    Secti...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #2: citation_manager\n",
            "\n",
            "ðŸ“š Adding citations...\n",
            "\n",
            "Tool #3: section_formatter\n",
            "\n",
            "ðŸ“ Formatting executive_summary section...\n",
            "\n",
            "Tool #4: append_to_report\n",
            "ðŸ“ Appended 'Executive Summary' to DEEP_RESEARCH_REPORT.md (total size: 4044 bytes)\n",
            "Now let me create the detailed sections for each strategic theme:\n",
            "Tool #5: content_writer\n",
            "\n",
            "âœï¸ Writing Workforce Transformation and Skills Evolution section\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Write a comprehensive, well-structured section for a research report.\n",
            "\n",
            "    Secti...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #6: section_formatter\n",
            "\n",
            "ðŸ“ Formatting main_section section...\n",
            "\n",
            "Tool #7: append_to_report\n",
            "ðŸ“ Appended 'Theme 1: Workforce Transformation and Skills Evolution' to DEEP_RESEARCH_REPORT.md (total size: 9147 bytes)\n",
            "\n",
            "Tool #8: content_writer\n",
            "\n",
            "âœï¸ Writing Economic Inequality and Societal Impact section\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Write a comprehensive, well-structured section for a research report.\n",
            "\n",
            "    Secti...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #9: append_to_report\n",
            "ðŸ“ Appended 'Theme 2: Economic Inequality and Societal Impact' to DEEP_RESEARCH_REPORT.md (total size: 13768 bytes)\n",
            "\n",
            "Tool #10: content_writer\n",
            "\n",
            "âœï¸ Writing Corporate Adaptation and Investment Strategies section\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Write a comprehensive, well-structured section for a research report.\n",
            "\n",
            "    Secti...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #11: append_to_report\n",
            "ðŸ“ Appended 'Theme 3: Corporate Adaptation and Investment Strategies' to DEEP_RESEARCH_REPORT.md (total size: 18672 bytes)\n",
            "\n",
            "Tool #12: content_writer\n",
            "\n",
            "âœï¸ Writing Future Directions and Recommendations section\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Write a comprehensive, well-structured section for a research report.\n",
            "\n",
            "    Secti...\n",
            "âœ… LLM response received.\n",
            "\n",
            "Tool #13: section_formatter\n",
            "\n",
            "ðŸ“ Formatting conclusion section...\n",
            "\n",
            "Tool #14: append_to_report\n",
            "ðŸ“ Appended 'Future Directions and Recommendations' to DEEP_RESEARCH_REPORT.md (total size: 26342 bytes)\n",
            "Perfect! I have successfully created a comprehensive research report on \"The Impact of Artificial Intelligence on Workforce: Future Directions\" and built it section by section in the DEEP_RESEARCH_REPORT.md file. The report is now complete with:\n",
            "\n",
            "1. **Executive Summary** - Overview of key findings and strategic themes\n",
            "2. **Theme 1: Workforce Transformation and Skills Evolution** - Detailed analysis of job displacement/creation patterns and skills evolution\n",
            "3. **Theme 2: Economic Inequality and Societal Impact** - Examination of inequality risks and policy requirements\n",
            "4. **Theme 3: Corporate Adaptation and Investment Strategies** - Analysis of successful corporate approaches and ROI metrics\n",
            "5. **Future Directions and Recommendations** - Synthesis of insights with actionable recommendations for all stakeholders\n",
            "6. **References** - Proper citations from authoritative sources\n",
            "\n",
            "The report presents the key insights from the analysis in a clear, actionable format:\n",
            "- Net +78M jobs by 2030 despite 92M displacements\n",
            "- 39% of skills evolving significantly\n",
            "- 6x ROI on corporate reskilling programs\n",
            "- 15% productivity gains from AI integration\n",
            "- Critical 2-year implementation window\n",
            "- Specific recommendations for policymakers, corporations, and workers\n",
            "\n",
            "Now I'll hand off to the critic_agent for review of the complete report.\n",
            "Tool #15: handoff_to_agent\n",
            "The comprehensive research report has been successfully created and is ready for review. The report transforms the analysis insights into a clear, actionable format that stakeholders can use to navigate the AI-driven workforce transformation effectively.I'll now read and evaluate the complete research report on \"The Impact of Artificial Intelligence on Workforce: Future Directions\" from the DEEP_RESEARCH_REPORT.md file.\n",
            "Tool #1: read_report\n",
            "ðŸ“– Read DEEP_RESEARCH_REPORT.md (26342 bytes, 3152 words, 258 lines)\n",
            "Now I'll evaluate the quality of this comprehensive research report using the quality checker tool.\n",
            "Tool #2: quality_checker\n",
            "\n",
            "ðŸ” Checking report quality\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Evaluate this research report for quality, completeness, and coherence.\n",
            "\n",
            "    Rep...\n",
            "âœ… LLM response received.\n",
            "Now I'll use the improvement suggester to provide detailed recommendations based on the quality assessment.\n",
            "Tool #3: improvement_suggester\n",
            "Let me fix the parameter format and try again:\n",
            "Tool #4: improvement_suggester\n",
            "\n",
            "ðŸ’¡ Generating improvement suggestions\n",
            "\n",
            "ðŸ¤– Invoking LLM for: Based on this quality assessment, provide specific, actionable suggestions to im...\n",
            "âœ… LLM response received.\n",
            "Based on my comprehensive review of the report, I can see there's a significant issue - the report appears to be complete in the file I read, contrary to what the quality checker indicated. Let me save my assessment and provide the final verdict.\n",
            "Tool #5: save_output\n",
            "ðŸ’¾ critic_agent saved output to: agent_outputs/critic_agent_assessment_20260220_204143.md\n",
            "---\n",
            "## Quality Assessment\n",
            "\n",
            "**Report File:** DEEP_RESEARCH_REPORT.md\n",
            "\n",
            "**Quality Score:** 0.85\n",
            "**Completeness Score:** 0.90\n",
            "**Coherence Score:** 0.82\n",
            "\n",
            "### Strengths\n",
            "- Excellent structure with clear executive summary and three thematic sections\n",
            "- Strong use of quantitative data (78M jobs created, 92M displaced, 39% skills evolution, 6x ROI, 15% productivity gains)\n",
            "- Comprehensive coverage of all three themes: workforce transformation, economic inequality, and corporate adaptation\n",
            "- Well-organized future directions with stakeholder-specific recommendations\n",
            "- Professional formatting and logical flow throughout\n",
            "- Actionable insights with clear implementation timelines (0-2 years, 2-5 years, 5-10 years)\n",
            "- Proper references section with credible sources (WEF, McKinsey, Goldman Sachs, IBM, etc.)\n",
            "\n",
            "### Areas for Improvement\n",
            "- Could benefit from a methodology section explaining data collection and analysis approaches\n",
            "- Some statistical claims would benefit from inline source attribution\n",
            "- Could include a limitations section acknowledging potential constraints\n",
            "- Table of contents would enhance navigation\n",
            "\n",
            "### Assessment Notes\n",
            "Upon careful review of the complete DEEP_RESEARCH_REPORT.md file, I found that the report is actually comprehensive and well-executed. All sections are complete including:\n",
            "- Executive Summary with clear thematic overview\n",
            "- Theme 1: Workforce Transformation and Skills Evolution (fully developed)\n",
            "- Theme 2: Economic Inequality and Societal Impact (complete with policy frameworks)\n",
            "- Theme 3: Corporate Adaptation and Investment Strategies (comprehensive analysis)\n",
            "- Future Directions and Recommendations (detailed stakeholder-specific guidance)\n",
            "- Proper References section\n",
            "\n",
            "The report effectively synthesizes research findings into actionable insights and emphasizes the critical 2-year implementation window for stakeholders to navigate AI workforce transformation successfully.\n",
            "\n",
            "### Verdict\n",
            "**APPROVED**\n",
            "\n",
            "The report meets high quality standards and provides valuable, actionable insights for policymakers, corporations, and workers navigating the AI-driven transformation of work. The research is thorough, well-structured, and addresses the urgent timeline for implementation effectively.\n",
            "\n",
            "---\n",
            "================================================================================\n",
            "RESEARCH COMPLETED\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Define the research topic\n",
        "research_topic = \"The impact of artificial intelligence on workforce: future directions\"\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"STARTING MULTI-AGENT DEEP RESEARCH\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nTopic: {research_topic}\")\n",
        "print(f\"\\nThe agents will now collaborate to produce a comprehensive research report...\\n\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "# Execute the swarm\n",
        "result = research_swarm(research_topic)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"RESEARCH COMPLETED\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyF6oZIzTZdE"
      },
      "source": [
        "## 8. View Results and Analysis\n",
        "\n",
        "Let's examine the results of our multi-agent collaboration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bYrcM_fTZdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3274ac68-98c0-46b8-a79b-3b31c2e42c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š EXECUTION SUMMARY\n",
            "================================================================================\n",
            "Status: Status.COMPLETED\n",
            "Total agents involved: 5\n",
            "\n",
            "Agent collaboration sequence:\n",
            "  1. planning_agent\n",
            "  2. research_agent\n",
            "  3. analysis_agent\n",
            "  4. writing_agent\n",
            "  5. critic_agent\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display final status\n",
        "print(f\"\\nðŸ“Š EXECUTION SUMMARY\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Status: {result.status}\")\n",
        "print(f\"Total agents involved: {len(result.node_history)}\")\n",
        "print(f\"\\nAgent collaboration sequence:\")\n",
        "for i, node in enumerate(result.node_history, 1):\n",
        "    print(f\"  {i}. {node.node_id}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JE4ybjhTZdF"
      },
      "source": [
        "## 9. Conclusion\n",
        "\n",
        "You've successfully built a multi-agent deep research assistant using:\n",
        "\n",
        "- **Strands Agents SDK** for agent framework\n",
        "- **AWS Bedrock** for LLM backend (Claude 4 Sonnet)\n",
        "- **Swarm Pattern** for autonomous multi-agent collaboration\n",
        "- **5 Specialized Agents** with 15 custom tools\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Agent Specialization**: Each agent has a clear role and specialized tools\n",
        "2. **Autonomous Collaboration**: Agents decide when to hand off tasks\n",
        "3. **Shared Context**: All agents have access to the full conversation history\n",
        "4. **Tool-Based Coordination**: The `handoff_to_agent` tool enables seamless transitions\n",
        "5. **Scalable Architecture**: Easy to add more agents or tools as needed\n",
        "6. **Use **file system** efficiently to manage tokens efficiently\n",
        "\n",
        "### Next Steps\n",
        "- Enhance instruction for Writing agent\n",
        "- Improve interactions with file system to manage context efficiently and optimize token usage\n",
        "- Add more specialized agents for your domain\n",
        "- Implement evaluation metrics\n",
        "- Explore other Strands patterns (Graph, Workflow)\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [Strands Agents Documentation](https://strandsagents.com/)\n",
        "- [AWS Bedrock Documentation](https://aws.amazon.com/bedrock/)\n",
        "- [Strands GitHub Repository](https://github.com/strands-agents/sdk-python)\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Building! ðŸš€**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}